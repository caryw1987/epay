server.port=8080
spring.application.name=epay-cache
####### database Config #######
spring.datasource.driver-class-name=com.mysql.jdbc.Driver
spring.datasource.type=com.alibaba.druid.pool.DruidDataSource
spring.datasource.url=jdbc:mysql://192.168.0.108:3306/epay?useUnicode=true&characterEncoding=utf-8&autoReconnect=true&zeroDateTimeBehavior=convertToNull&allowMultiQueries=true
spring.datasource.username=root
spring.datasource.password=root
# MyBatis
mybatis.mapper-locations=classpath:/mybatis/*Mapper.xml
mapper.identity=MYSQL
# Redis
spring.redis.cluster.nodes=192.168.0.107:7001,192.168.0.107:7002,192.168.0.109:7003,192.168.0.109:7004,192.168.0.110:7005,192.168.0.110:7006
spring.redis.cluster.maxTotal=200
spring.redis.cluster.maxIdle=8
spring.redis.cluster.minIdle=2
# ehcache
spring.cache.jcache.config=classpath:ehcache.xml

# ------------------------------------- kafka -------------------------------------
# 整体配置
spring.kafka.bootstrap-servers=192.168.0.107:9092,192.168.0.109:9092,192.168.0.110:9092
spring.kafka.listener.missing-topics-fatal=false
# 消费者配置
spring.kafka.consumer.enable-auto-commit=false
spring.kafka.consumer.auto-commit-interval=1000ms
spring.kafka.consumer.auto-offset-reset=earliest
spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializer
spring.kafka.consumer.value-deserializer=org.apache.kafka.common.serialization.StringDeserializer
# 生产者配置
spring.kafka.producer.key-serializer=org.apache.kafka.common.serialization.StringSerializer
spring.kafka.producer.value-serializer=org.apache.kafka.common.serialization.StringSerializer

# ------------------------------------- zookeeper -------------------------------------
#zookeeper地址
zookeeper.curator.connectString=192.168.0.107:2181,192.168.0.109:2181,192.168.0.110:2181
#客户端尝试连接ZK的重试次数
zookeeper.curator.retryCount=3
#客户端尝试连接ZK的重试间隔时间
zookeeper.curator.elapsedTimeMs=5000
#客户端session超时时间，超时后临时节点会被自动删除
zookeeper.curator.sessionTimeoutMs=60000
#客户端尝试连接ZK的连接超时时间
zookeeper.curator.connectionTimeoutMs=5000